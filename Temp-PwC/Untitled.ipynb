{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e290ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install pytorch_lightning\n",
    "    !pip install neuralforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7579f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import neuralforecast as nf\n",
    "from neuralforecast.data.datasets.epf import EPF\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from neuralforecast.data.tsloader import TimeSeriesLoader\n",
    "from neuralforecast.experiments.utils import create_datasets\n",
    "from neuralforecast.data.tsdataset import IterateWindowsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a496c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # Comment out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f48b4a",
   "metadata": {},
   "source": [
    "# Hyperparameter Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729405e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PERC = .1\n",
    "TEST_PERC = .1\n",
    "N_TIME_SERIES = 862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d201c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = {}\n",
    "\n",
    "mc_model['seq_len'] = 96 # Input sequence size.\n",
    "mc_model['label_len'] = 96 // 2 # Label sequence size. (Input buffer length for decoder)\n",
    "mc_model['pred_len'] = 96 # Prediction sequence size.\n",
    "mc_model['output_attention'] = False # If true use output attention for Transformer model.\n",
    "mc_model['enc_in'] = N_TIME_SERIES #  Number of encoders in data embedding layers.\n",
    "mc_model['dec_in'] = N_TIME_SERIES #  Number of decoders in data embedding layers.\n",
    "mc_model['d_model'] = 512 #  Number of nodes for embedding layers.\n",
    "mc_model['c_out'] = N_TIME_SERIES # Number of output nodes in projection layer.\n",
    "mc_model['embed'] = 'timeF' #  Type of embedding layers.\n",
    "mc_model['freq'] = 'h' # Frequency for embedding layers.\n",
    "mc_model['dropout'] = 0.05 # Float between (0, 1). Dropout for Transformer.\n",
    "mc_model['factor'] = 1 # Factor for attention layer.\n",
    "mc_model['n_heads'] = 8 #  Number of heads in attention layer.\n",
    "mc_model['d_ff'] = 2_048 #  Number of inputs in encoder layers.\n",
    "mc_model['moving_avg'] = 25  #  Moving average for encoder and decoder layers.\n",
    "mc_model['activation'] = 'gelu' #  Activation function for encoder layer.\n",
    "mc_model['e_layers'] = 2 # Number of encoder layers.\n",
    "mc_model['d_layers'] = 1 # Number of decoder layers.\n",
    "mc_model['loss_train'] = 'MAE' # Loss to optimize. An item from ['MAPE', 'MASE', 'SMAPE', 'MSE', 'MAE', 'QUANTILE', 'QUANTILE2']. \n",
    "mc_model['loss_hypar'] = 0.5 # Hyperparameter for chosen loss.\n",
    "mc_model['loss_valid'] = 'MAE'# Validation loss.An item from ['MAPE', 'MASE', 'SMAPE', 'RMSE', 'MAE', 'QUANTILE'].\n",
    "mc_model['learning_rate'] = 0.001 # Learning rate between (0, 1).\n",
    "mc_model['lr_decay'] = 0.5 # Decreasing multiplier for the learning rate.\n",
    "mc_model['weight_decay'] = 0. # L2 penalty for optimizer.\n",
    "mc_model['lr_decay_step_size'] = 2 # Steps between each learning rate decay.\n",
    "mc_model['random_seed'] = 1 # random_seed for pseudo random pytorch initializer and numpy random generator.\n",
    "\n",
    "\n",
    "# Dataset parameters\n",
    "mc_data = {}\n",
    "mc_data['mode'] = 'iterate_windows'\n",
    "mc_data['n_time_in'] = mc_model['seq_len'] # Input sequence length\n",
    "mc_data['n_time_out'] = mc_model['pred_len'] # Prediction sequence length\n",
    "mc_data['batch_size'] = 1 # Batch size \n",
    "mc_data['normalizer_y'] = None \n",
    "mc_data['normalizer_x'] = None\n",
    "mc_data['max_epochs'] = 1 # Maximum number of training epochs\n",
    "mc_data['max_steps'] = None # maximum number of training steps\n",
    "mc_data['early_stop_patience'] = 20 #Number of consecutive violations of early stopping criteria to end training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a01b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df, S_df = nf.data.datasets.long_horizon.LongHorizon.load('autoformer_data', 'TrafficL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa352b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>AUD_CLOSE</th>\n",
       "      <th>DKK_CLOSE</th>\n",
       "      <th>EUR_CLOSE</th>\n",
       "      <th>HKD_CLOSE</th>\n",
       "      <th>JPY_CLOSE</th>\n",
       "      <th>MXN_CLOSE</th>\n",
       "      <th>NZD_CLOSE</th>\n",
       "      <th>NOK_CLOSE</th>\n",
       "      <th>SEK_CLOSE</th>\n",
       "      <th>CHF_CLOSE</th>\n",
       "      <th>GBP_CLOSE</th>\n",
       "      <th>USD_CLOSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.5100</td>\n",
       "      <td>0.141970</td>\n",
       "      <td>0.009271</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>2.2199</td>\n",
       "      <td>1.1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.5100</td>\n",
       "      <td>0.141740</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>2.2055</td>\n",
       "      <td>1.1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>0.141496</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>2.1999</td>\n",
       "      <td>1.1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-05-04</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.5100</td>\n",
       "      <td>0.141616</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>2.2075</td>\n",
       "      <td>1.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-05-05</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.5100</td>\n",
       "      <td>0.141616</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>2.2075</td>\n",
       "      <td>1.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>1.0218</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>1.4684</td>\n",
       "      <td>0.173684</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>0.07215</td>\n",
       "      <td>0.9477</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>1.3568</td>\n",
       "      <td>1.7280</td>\n",
       "      <td>1.3511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>1.0224</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>1.4837</td>\n",
       "      <td>0.174374</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.07183</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>1.3661</td>\n",
       "      <td>1.7407</td>\n",
       "      <td>1.3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>1.0176</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>1.4847</td>\n",
       "      <td>0.174965</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.07098</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>1.3707</td>\n",
       "      <td>1.7493</td>\n",
       "      <td>1.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>1.0176</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>1.4815</td>\n",
       "      <td>0.175103</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.07151</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.1543</td>\n",
       "      <td>1.3704</td>\n",
       "      <td>1.7584</td>\n",
       "      <td>1.3624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>1.0222</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>1.4870</td>\n",
       "      <td>0.175485</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.1541</td>\n",
       "      <td>1.3719</td>\n",
       "      <td>1.7679</td>\n",
       "      <td>1.3650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3651 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  AUD_CLOSE  DKK_CLOSE  EUR_CLOSE  HKD_CLOSE  JPY_CLOSE  \\\n",
       "0    2007-05-01     0.9200     0.2000     1.5100   0.141970   0.009271   \n",
       "1    2007-05-02     0.9100     0.2000     1.5100   0.141740   0.009232   \n",
       "2    2007-05-03     0.9100     0.2000     1.5000   0.141496   0.009190   \n",
       "3    2007-05-04     0.9100     0.2000     1.5100   0.141616   0.009218   \n",
       "4    2007-05-05     0.9100     0.2000     1.5100   0.141616   0.009218   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3646 2017-04-24     1.0218     0.1974     1.4684   0.173684   0.012310   \n",
       "3647 2017-04-25     1.0224     0.1994     1.4837   0.174374   0.012210   \n",
       "3648 2017-04-26     1.0176     0.1995     1.4847   0.174965   0.012260   \n",
       "3649 2017-04-27     1.0176     0.1992     1.4815   0.175103   0.012250   \n",
       "3650 2017-04-28     1.0222     0.1999     1.4870   0.175485   0.012250   \n",
       "\n",
       "      MXN_CLOSE  NZD_CLOSE  NOK_CLOSE  SEK_CLOSE  CHF_CLOSE  GBP_CLOSE  \\\n",
       "0       0.10000     0.8200     0.1860     0.1700     0.9100     2.2199   \n",
       "1       0.10000     0.8200     0.1854     0.1700     0.9100     2.2055   \n",
       "2       0.10000     0.8100     0.1847     0.1600     0.9100     2.1999   \n",
       "3       0.10000     0.8100     0.1854     0.1600     0.9100     2.2075   \n",
       "4       0.10000     0.8100     0.1854     0.1600     0.9100     2.2075   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3646    0.07215     0.9477     0.1579     0.1525     1.3568     1.7280   \n",
       "3647    0.07183     0.9426     0.1586     0.1548     1.3661     1.7407   \n",
       "3648    0.07098     0.9382     0.1585     0.1554     1.3707     1.7493   \n",
       "3649    0.07151     0.9369     0.1590     0.1543     1.3704     1.7584   \n",
       "3650    0.07253     0.9373     0.1590     0.1541     1.3719     1.7679   \n",
       "\n",
       "      USD_CLOSE  \n",
       "0        1.1105  \n",
       "1        1.1087  \n",
       "2        1.1066  \n",
       "3        1.1075  \n",
       "4        1.1075  \n",
       "...         ...  \n",
       "3646     1.3511  \n",
       "3647     1.3565  \n",
       "3648     1.3612  \n",
       "3649     1.3624  \n",
       "3650     1.3650  \n",
       "\n",
       "[3651 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filename = \"/ssd003/projects/forecasting_bootcamp/bootcamp_datasets/boc_exchange/dataset.csv\"\n",
    "# DATA_PATH = \"/ssd003/projects/forecasting_bootcamp/bootcamp_datasets/electricity/electricity.csv\"\n",
    "data_df = pd.read_csv(data_filename, index_col=0)\n",
    "data_df.index = pd.to_datetime(data_df.index)\n",
    "data_df = data_df.reset_index().rename({'index':'date'}, axis=1)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa13fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8049e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
