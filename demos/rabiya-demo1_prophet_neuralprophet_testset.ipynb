{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prospective-broad",
   "metadata": {},
   "source": [
    "![Forecasting Demo 1: Baselines, Prophet, and NeuralProphet](https://raw.githubusercontent.com/VectorInstitute/forecasting-bootcamp/media-assets-do-not-merge/forecasting-demo-1.png?token=GHSAT0AAAAAABQMCWQFQHUMDN4MVB2LEQDUYQ7WXUQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-utilization",
   "metadata": {
    "id": "SYomKW1s04Sg"
   },
   "source": [
    "This notebook is the first of a series that introduces the application of popular, recently developed time series forecasting methods. In particular, we emphasize the use of consistent evaluation metrics and analysis across all models and model configurations. \n",
    "\n",
    "Use these notebooks as tools to explore the application of various forecasting methods to multivariate time series datasets, and to inspire an experimental approach for comparing multiple models and model configurations.\n",
    "\n",
    "This notebook explores the application of **Prophet** and **NeuralProphet** to exchange rate forecasting, as well as two baseline methods using **sktime**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "institutional-pollution",
   "metadata": {
    "id": "inside-wireless"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install prophet\n",
    "    !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "    #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes\n",
    "    !pip install sktime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-sunset",
   "metadata": {
    "id": "MsovnLdhfwsu"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defensive-bobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd003/home/rnoori/forecasting-bootcamp/demos\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-cursor",
   "metadata": {
    "id": "diverse-eight"
   },
   "source": [
    "### Load bitcoin data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "purple-folder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>16687.912109</td>\n",
       "      <td>16947.058594</td>\n",
       "      <td>16564.611328</td>\n",
       "      <td>16697.777344</td>\n",
       "      <td>16697.777344</td>\n",
       "      <td>26862218609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>16696.220703</td>\n",
       "      <td>16797.876953</td>\n",
       "      <td>16570.410156</td>\n",
       "      <td>16711.546875</td>\n",
       "      <td>16711.546875</td>\n",
       "      <td>16106223492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>16712.919922</td>\n",
       "      <td>16746.779297</td>\n",
       "      <td>16248.692383</td>\n",
       "      <td>16291.832031</td>\n",
       "      <td>16291.832031</td>\n",
       "      <td>21313378652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>16291.223633</td>\n",
       "      <td>16291.223633</td>\n",
       "      <td>15599.046875</td>\n",
       "      <td>15787.284180</td>\n",
       "      <td>15787.284180</td>\n",
       "      <td>37429485518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>15778.548828</td>\n",
       "      <td>16202.363281</td>\n",
       "      <td>15656.606445</td>\n",
       "      <td>16202.363281</td>\n",
       "      <td>16202.363281</td>\n",
       "      <td>35892744192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  \\\n",
       "0    2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1    2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2    2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3    2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4    2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "2984 2022-11-18  16687.912109  16947.058594  16564.611328  16697.777344   \n",
       "2985 2022-11-19  16696.220703  16797.876953  16570.410156  16711.546875   \n",
       "2986 2022-11-20  16712.919922  16746.779297  16248.692383  16291.832031   \n",
       "2987 2022-11-21  16291.223633  16291.223633  15599.046875  15787.284180   \n",
       "2988 2022-11-22  15778.548828  16202.363281  15656.606445  16202.363281   \n",
       "\n",
       "         Adj Close       Volume  \n",
       "0       457.334015     21056800  \n",
       "1       424.440002     34483200  \n",
       "2       394.795990     37919700  \n",
       "3       408.903992     36863600  \n",
       "4       398.821014     26580100  \n",
       "...            ...          ...  \n",
       "2984  16697.777344  26862218609  \n",
       "2985  16711.546875  16106223492  \n",
       "2986  16291.832031  21313378652  \n",
       "2987  15787.284180  37429485518  \n",
       "2988  16202.363281  35892744192  \n",
       "\n",
       "[2989 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filename = \"/ssd003/home/rnoori/forecasting-bootcamp/datasets/BTC-USD.csv\"\n",
    "data_df = pd.read_csv(data_filename, index_col=0)\n",
    "data_df.index = pd.to_datetime(data_df.index)\n",
    "data_df = data_df.reset_index().rename({'index':'Date'}, axis=1)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-latin",
   "metadata": {
    "id": "lined-nicholas"
   },
   "source": [
    "### Split data according to use case\n",
    "\n",
    "For simplicity, this notebook uses a conventional training and testing split over the dataset. Other notebooks will give examples of rolling cross validation using multiple validation periods given by a set of cutoff dates. \n",
    "\n",
    "The purpose of this notebook is to explore a simpler problem formulation using multiple models. The experiments and analysis can be easily adapted for rolling cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cathedral-treasurer",
   "metadata": {
    "id": "raised-uniform"
   },
   "outputs": [],
   "source": [
    "lag_time = 60\n",
    "lead_time = 7\n",
    "\n",
    "train_size = 0.8\n",
    "\n",
    "train_df = data_df.iloc[:int(len(data_df)*train_size)]\n",
    "test_df = data_df.iloc[int(len(data_df)*train_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-stick",
   "metadata": {},
   "source": [
    "To ensure that we have enough data for testing, we need to withhold at least `lag_time + lead_time` observations from the dataset. Assuming we want to test a fitted model on all available examples in the test set, the number of testing examples can be computed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unnecessary-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Timesteps in test_df: 598\n",
      "Number of test examples: 532\n"
     ]
    }
   ],
   "source": [
    "n_test_cases = len(test_df) - lag_time - lead_time + 1\n",
    "print(f\"   Timesteps in test_df: {len(test_df)}\")\n",
    "print(f\"Number of test examples: {n_test_cases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-aluminum",
   "metadata": {},
   "source": [
    "### Iterating over test examples\n",
    "\n",
    "To help with iterating over valid pairs of input and target data, we define a PyTorch-like dataset class. In this notebook, we'll use this primarily for iterating over test examples, since both Prophet and NeuralProphet impose their own, special formats for passing in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "excess-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingDataset:\n",
    "\n",
    "    def __init__(self, data_df, lag_time, lead_time, feature_columns):\n",
    "        self.n_examples = len(data_df) - lag_time - lead_time + 1\n",
    "        assert self.n_examples > 0, \"Dataset must contain at least one example.\"\n",
    "        assert \"Date\" in data_df.columns, \"Source DataFrame must contain a date/ds column.\"\n",
    "\n",
    "        self.df = data_df[feature_columns]\n",
    "        if 'Date' in data_df.columns:\n",
    "            self.dates = data_df.Date\n",
    "#         elif 'ds' in data_df.columns:\n",
    "#             self.dates = data_df.ds\n",
    "        self.lag_time = lag_time\n",
    "        self.lead_time = lead_time\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.df.iloc[idx:idx+lag_time]\n",
    "        output = self.df.iloc[idx+lag_time:idx+lag_time+lead_time]\n",
    "        input_dates = self.dates[idx:idx+lag_time]\n",
    "        output_dates = self.dates[idx+lag_time:idx+lag_time+lead_time]\n",
    "        return input, output, input_dates, output_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-orientation",
   "metadata": {},
   "source": [
    "Next, we instantiate an indexable `test_dataset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "turkish-thing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "juvenile-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['Open', 'High', 'Low', 'Volume']\n",
    "test_dataset = ForecastingDataset(test_df, lag_time, lead_time, feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-northwest",
   "metadata": {
    "id": "announced-debate"
   },
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "In order to objectively compare the performance of this and other models on out-of-sample forecasting performance, we will need to collect output in a consistent format and apply a suite of standard evaluation metrics:\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "See the article [Time Series Forecast Error Metrics You Should Know](https://towardsdatascience.com/time-series-forecast-error-metrics-you-should-know-cc88b8c67f27) for an overview of these and other popular forecasting error metrics. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "laden-nothing",
   "metadata": {
    "id": "ambient-drink"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "metrics = {\n",
    "    'mse': mean_squared_error,\n",
    "    'rmse': lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    'mae': mean_absolute_error,\n",
    "    'mape': mean_absolute_percentage_error\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "expired-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_statistics(error_metrics_dict, exp_name):\n",
    "    return {\n",
    "        'mean': pd.DataFrame(error_metrics_dict).mean(axis=0).rename(f'{exp_name}_mean_metrics'),\n",
    "        'std': pd.DataFrame(error_metrics_dict).std(axis=0).rename(f'{exp_name}_std_metrics'),\n",
    "        'max': pd.DataFrame(error_metrics_dict).max(axis=0).rename(f'{exp_name}_max_metrics'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-prague",
   "metadata": {},
   "source": [
    "# Baseline Forecasts\n",
    "\n",
    "Let's begin our experiments by producing forecasts using naïve estimators. A common baseline is *persistence forecasting*, where the forecast is simply an extension of the last known observation of the time series. A second baseline is the *mean window forecast*, where we take the mean over a window of observations and use this value for forecasts. The following code produces and collects the baseline forecasts into lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "returning-pride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open          High           Low        Volume\n",
      "2391  57604.839844  58913.746094  57168.675781   50749662970\n",
      "2392  58760.875000  59891.296875  57694.824219   60706272115\n",
      "2393  59171.933594  59479.578125  57646.808594   66058027988\n",
      "2394  58186.507813  58731.144531  55604.023438   75645303584\n",
      "2395  56099.914063  58338.738281  55879.085938   53053855641\n",
      "2396  58326.562500  58937.046875  57807.863281   46655208546\n",
      "2397  58253.777344  61276.664063  58038.707031   58238470525\n",
      "2398  59846.230469  60790.554688  59289.796875   46280252580\n",
      "2399  60175.945313  61253.035156  59589.875000   51828688519\n",
      "2400  59890.019531  63742.285156  59869.957031   69983454362\n",
      "2401  63523.753906  64863.097656  61554.796875   77451779687\n",
      "2402  63075.195313  63821.671875  62208.964844   60954381579\n",
      "2403  63258.503906  63594.722656  60222.531250   84293007468\n",
      "2404  61529.921875  62572.175781  60361.351563   66138759198\n",
      "2405  60701.886719  61057.457031  52829.535156   97468872758\n",
      "2406  56191.585938  57520.054688  54368.593750   65344865159\n",
      "2407  55681.792969  57062.148438  53448.046875   67849323955\n",
      "2408  56471.128906  56757.972656  53695.468750   54926612466\n",
      "2409  53857.105469  55410.230469  50583.812500   74798630778\n",
      "2410  51739.808594  52120.792969  47714.664063   86668667320\n",
      "2411  51143.226563  51167.562500  48805.285156   49014494781\n",
      "2412  50052.832031  50506.019531  47159.484375   46117114240\n",
      "2413  49077.792969  54288.003906  48852.796875   58284039825\n",
      "2414  54030.304688  55416.964844  53319.187500   49448222757\n",
      "2415  55036.636719  56227.207031  53887.917969   48000572955\n",
      "2416  54858.089844  55115.843750  52418.027344   46088929780\n",
      "2417  53568.664063  57900.718750  53129.601563   52395931985\n",
      "2418  57714.664063  58448.339844  57052.273438   42836427360\n",
      "2419  57825.863281  57902.593750  56141.906250   38177405335\n",
      "2420  56620.273438  58973.308594  56590.871094   51713139031\n",
      "2421  57214.179688  57214.179688  53191.425781   68564706967\n",
      "2422  53252.164063  57911.363281  52969.054688   69241316747\n",
      "2423  57441.308594  58363.316406  55382.507813   69523285106\n",
      "2424  56413.953125  58606.632813  55321.847656   68434023376\n",
      "2425  57352.765625  59464.613281  56975.210938   65382980634\n",
      "2426  58877.390625  59210.882813  56482.003906   65906690347\n",
      "2427  58250.871094  59519.355469  54071.457031   71776546298\n",
      "2428  55847.242188  56872.542969  54608.652344   61308396325\n",
      "2429  56714.531250  57939.363281  49150.535156   75215403907\n",
      "2430  49735.433594  51330.843750  46980.019531   96721152926\n",
      "2431  49682.980469  51438.117188  48868.578125   55737497453\n",
      "2432  49855.496094  50639.664063  46664.140625   59161047474\n",
      "2433  46716.636719  49720.042969  43963.351563   64047871555\n",
      "2434  46415.898438  46623.558594  42207.289063   74903638450\n",
      "2435  43488.058594  45812.457031  42367.832031   56187365084\n",
      "2436  42944.976563  43546.117188  30681.496094  126358098747\n",
      "2437  36753.667969  42462.984375  35050.617188   88281943359\n",
      "2438  40596.949219  42172.171875  33616.453125   82051616861\n",
      "2439  37371.031250  38831.054688  35383.683594   57377273240\n",
      "2440  37531.449219  38289.218750  31227.339844   78469274361\n",
      "2441  34700.363281  39835.140625  34551.082031   67359584098\n",
      "2442  38795.781250  39776.351563  36581.429688   56211915803\n",
      "2443  38392.625000  40782.078125  37905.835938   51346735160\n",
      "2444  39316.890625  40379.617188  37247.902344   43210968721\n",
      "2445  38507.082031  38856.968750  34779.039063   55200191952\n",
      "2446  35684.156250  37234.500000  33693.929688   45231013335\n",
      "2447  34607.406250  36400.667969  33520.738281   31646080921\n",
      "2448  35658.593750  37468.250000  34241.945313   39009847639\n",
      "2449  37293.792969  37896.734375  35787.085938   34639423297\n",
      "2450  36699.921875  38231.339844  35966.308594   33070867190\n",
      "              Open          High           Low       Volume\n",
      "2451  37599.410156  39478.953125  37243.972656  35460750427\n",
      "2452  39242.484375  39242.484375  35717.722656  41831090187\n",
      "2453  36880.156250  37917.714844  34900.414063  35959473399\n",
      "2454  35538.609375  36436.421875  35304.578125  28913440585\n",
      "2455  35835.265625  36790.570313  33480.640625  33683936663\n",
      "2456  33589.519531  34017.386719  31114.443359  49902050442\n",
      "2457  33416.976563  37537.371094  32475.865234  53972919008\n"
     ]
    }
   ],
   "source": [
    "x, y, x_d, y_d = test_dataset[0]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_persistence = NaiveForecaster(strategy='last')\n",
    "baseline_model_mean = NaiveForecaster(strategy='mean',window_length=lag_time)\n",
    "\n",
    "forecasts_persistence = []\n",
    "forecasts_mean = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    x, y, x_d, y_d = test_dataset[i]\n",
    "    \n",
    "    persistence_fc = baseline_model_persistence.fit_predict(x['Adj Close'], fh=list(range(1, lead_time+1)))\n",
    "    persistence_fc = pd.Series(persistence_fc.values, index=y_d)\n",
    "    forecasts_persistence.append(persistence_fc)\n",
    "\n",
    "    mean_fc = baseline_model_mean.fit_predict(x['USD_CLOSE'], fh=list(range(lead_time)))\n",
    "    mean_fc = pd.Series(mean_fc.values, index=y_d)\n",
    "    forecasts_mean.append(mean_fc)\n",
    "\n",
    "    print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-garage",
   "metadata": {},
   "source": [
    "### Compute error metrics over the baseline forecasts\n",
    "\n",
    "In this notebook, we want to compare the performance of experimental models (Prophet, NeuralProphet) compared to baselines (persistence and mean window extension). The following code applies each of the four evaluation metrics for every example in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_baseline_error_metrics(forecasts, test_dataset):\n",
    "\n",
    "    errors = {metric_name:[] for metric_name in metrics.keys()}\n",
    "\n",
    "    for i in range(len(forecasts)):\n",
    "        \n",
    "        fc = forecasts[i]\n",
    "        x, y, x_d, y_d = test_dataset[i]\n",
    "    \n",
    "        for metric_name, metric_fn in metrics.items(): \n",
    "                errors[metric_name].append(metric_fn(y_true=y['USD_CLOSE'], y_pred=fc))\n",
    "\n",
    "    return errors, forecasts\n",
    "\n",
    "persistence_errors, _ = compute_baseline_error_metrics(forecasts_persistence, test_dataset)\n",
    "mean_errors, _ = compute_baseline_error_metrics(forecasts_mean, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-chase",
   "metadata": {},
   "source": [
    "The following code uses the function `compute_error_statistics` to reduce the mean evaluation metrics over the entire test set to three statistics (mean, standard deviation, and max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_stats = compute_error_statistics(persistence_errors, 'persistence')\n",
    "persistence_stats['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_window_stats = compute_error_statistics(mean_errors, 'mean_window')\n",
    "mean_window_stats['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-baltimore",
   "metadata": {},
   "source": [
    "We now collect the mean evaluation statistics for each metric into a DataFrame so that we can later compare these to experimental models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(persistence_stats['mean']).T\n",
    "results_df = results_df.append(mean_window_stats['mean'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-approach",
   "metadata": {},
   "source": [
    "### Visualizing forecasts over the test set\n",
    "\n",
    "For each example in the test set, we have produced a forecast between `1` and `lead_time` days into the future. As we will see later, this is difficult to visualize over the whole test set. Instead, we can visualize the value of each forecast at a single time step into the future. The code below visualizes the baseline forecasts at the maximum lead time. As we can see, the persistence forecast is exactly the ground truth shifted `lead_time` days into the future. In the context of exchange rate forecasting, this baseline may be difficult to beat.\n",
    "\n",
    "#### Persistence Forecasts At Max Lead Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fcs = [{'date': fc.index[-1:][0], 'yhat':fc[-1:][0]} for fc in forecasts_persistence]\n",
    "max_fcs = pd.DataFrame(max_fcs)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(test_df.date, test_df['USD_CLOSE'], color='blue', label='ground truth')\n",
    "plt.plot(max_fcs.date, max_fcs.yhat, color='red', label='forecast')\n",
    "plt.title(f\"Forecasts at max lead time ({lead_time} samples) - Persistence\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth\n",
    "plt.figure(figsize=(12,3))\n",
    "ground_truth = test_df[['date', 'USD_CLOSE']]\n",
    "plt.plot(ground_truth.date, ground_truth['USD_CLOSE'], label='ground truth')\n",
    "\n",
    "# Plot example single forecast\n",
    "plt.plot(forecasts_persistence[-1], label='forecast')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-queensland",
   "metadata": {},
   "source": [
    "#### Mean Window Forecasts At Max Lead Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fcs = [{'date': fc.index[-1:][0], 'yhat':fc[-1:][0]} for fc in forecasts_mean]\n",
    "max_fcs = pd.DataFrame(max_fcs)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(test_df.date, test_df['USD_CLOSE'], color='blue', label='ground truth')\n",
    "plt.plot(max_fcs.date, max_fcs.yhat, color='red', label='forecast')\n",
    "plt.title(f\"Forecasts at max lead time ({lead_time} samples) - Mean Window\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth\n",
    "plt.figure(figsize=(12,3))\n",
    "ground_truth = test_df[['date', 'USD_CLOSE']]\n",
    "plt.plot(ground_truth.date, ground_truth['USD_CLOSE'], label='ground truth')\n",
    "\n",
    "# Plot example single forecast\n",
    "plt.plot(forecasts_mean[-1], label='forecast')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-newsletter",
   "metadata": {
    "id": "latin-atlas"
   },
   "source": [
    "# Prophet\n",
    "\n",
    "Univariate forecasting that supports additional *future* regressors. Prophet does not support the inclusion of *lagged regressors*, i.e. it does not support the use of historical values of multiple series to predict a single target series. We include it as a baseline because it is popular, lightweight, interpretable, and performs very well in some domains. \n",
    "\n",
    "Prophet is based on a Generalized Additive Model (GAM):\n",
    "\n",
    "$ y(t) = g(t) + s(t) + h(t) + \\epsilon_t$\n",
    "\n",
    "where $y(t)$ is the target series, $g(t)$ is the trend function, $s(t)$ is the seasonality or periodic function, $h(t)$ is a function reflecting holidays or other irregular events, and $\\epsilon_t$ is an error term that is assumed to be normally distributed.\n",
    "\n",
    "Despite being formulated as an additive model, multiplicative interaction between seasonality and trend components is supported (using a log transform). In the implementation, this is easily configurable using a constructor parameter. See the [documentation](https://facebook.github.io/prophet/docs/multiplicative_seasonality.html) for more details.\n",
    "\n",
    "#### Data Preparation\n",
    "\n",
    "Prophet, like most forecasting packages, imposes its own, specific format for input data. It expects inputs in the form of a Pandas DataFrame with two columns, `ds` and `y`, which correspond to Pandas-formatted timestamps and the target time series, respectively.\n",
    "\n",
    "In this example, we create a Prophet DataFrame by selecting the columns `date` and `USD_CLOSE` from the Bank of Canada exchange rate dataset. We then rename those columns to `ds` and `y`, respectively. \n",
    "\n",
    "Note that the `ds` column is already correctly formatted using the Pandas datetime format, since we converted it immediately after loading the data. When reading CSVs, always be sure to check that datestamps are properly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-numbers",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "generous-glasgow",
    "outputId": "90affa3b-a381-42a5-e6db-72f5160a3640"
   },
   "outputs": [],
   "source": [
    "prophet_model_df = train_df[['date', 'USD_CLOSE']]\n",
    "prophet_model_df = train_df.rename({'date':'ds', 'USD_CLOSE':'y'}, axis=1)\n",
    "prophet_model_df = prophet_model_df[['ds', 'y']]\n",
    "prophet_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-allocation",
   "metadata": {
    "id": "ideal-injury"
   },
   "source": [
    "### Model Initialization and Fitting\n",
    "\n",
    "For our baseline model, we fit Prophet using its default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-arrest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blond-stamp",
    "outputId": "ac3aaa63-501a-45b4-b715-77e569bd5c6f"
   },
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model = model.fit(prophet_model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-austria",
   "metadata": {
    "id": "facial-tracker"
   },
   "source": [
    "### Produce Forecasts\n",
    "\n",
    "To produce a forecast using a fitted Prophet model, we need to pass it a dataframe with the desired timestamps in a column named `ds`. In the example below, we use the fitted model object to produce a dataframe `future` with dates that extend `len(test_df)` days beyond the training dates. Passing `future` to the fitted model's `predict` function will return a dataframe populated with a detailed forecast, including model component values and confidence ranges.\n",
    "\n",
    "Notice here that we are asking Prophet to produce a single forecast for the entire test period. We are doing this because Prophet does not support inference using fixed-sized inputs in the same way that every other technique considered in our bootcamp does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-visit",
   "metadata": {
    "id": "twenty-ghana"
   },
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=len(test_df))\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-broadcast",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "identical-affair",
    "outputId": "49d90418-c170-47d3-c353-5ad5c5fdd4f2"
   },
   "outputs": [],
   "source": [
    "forecast.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-elements",
   "metadata": {
    "id": "racial-section"
   },
   "source": [
    "### Plotting Prophet Forecasts\n",
    "\n",
    "The following code visualizes the application of the fitted Prophet model to both in-sample (training) and out-of-sample (testing) data. Visualization and evaluation of forecasting models using out-of-sample data is crucial for estimating future performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-brighton",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "undefined-drove",
    "outputId": "3532204b-1528-4959-dd55-cee4cdf913b6"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "ax.fill_between(forecast.ds.iloc[:-len(test_df)], \n",
    "    forecast.yhat_lower.iloc[:-len(test_df)], \n",
    "    forecast.yhat_upper.iloc[:-len(test_df)],\n",
    "    color='blue', label='In-Sample confidence interval (80%)', alpha=0.15)\n",
    "\n",
    "ax.fill_between(forecast.ds.iloc[-len(test_df):], \n",
    "    forecast.yhat_lower.iloc[-len(test_df):], \n",
    "    forecast.yhat_upper.iloc[-len(test_df):],\n",
    "    color='red', label='Out-of-Sample confidence interval (80%)', alpha=0.1)\n",
    "\n",
    "ax.scatter(prophet_model_df.ds, prophet_model_df['y'], color='slategrey', s=3, linewidths=0, label='Train Samples')\n",
    "ax.scatter(test_df.date, test_df['USD_CLOSE'], color='salmon', s=3, linewidths=0, label='Test Samples')\n",
    "\n",
    "ax.plot(forecast.ds.iloc[:-len(test_df)], \n",
    "        forecast.yhat.iloc[:-len(test_df)], color='blue', label='In-Sample Forecast')\n",
    "\n",
    "ax.plot(forecast.ds.iloc[-len(test_df):], forecast.yhat.iloc[-len(test_df):], \n",
    "        color='red', label='Out-of-Sample Forecast')\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-royalty",
   "metadata": {},
   "source": [
    "### Prophet Forecasts At Max Lead Time\n",
    "\n",
    "As we did with the baseline methods, let's visualize Prophet's forecasts at maximum lead time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use our ForecastingDataset class to help with formatting Prophet's output.\n",
    "forecast_eval_dataset = ForecastingDataset(forecast.iloc[-len(test_df):], lag_time, lead_time, ['yhat'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "\n",
    "forecasts_at_max_lead = []\n",
    "dates_at_max_lead = []\n",
    "\n",
    "for i in range(len(forecast_eval_dataset)):\n",
    "    x, y, x_d, y_d = forecast_eval_dataset[i]\n",
    "    x_gt, y_gt, x_gt_d, y_gt_d = test_dataset[i]\n",
    "\n",
    "    forecasts_at_max_lead.append(y.values[-1])\n",
    "    dates_at_max_lead.append(y_d.values[-1])\n",
    "\n",
    "ax.plot(dates_at_max_lead, forecasts_at_max_lead, color='red', label='forecast')\n",
    "ax.plot(test_df.date, test_df['USD_CLOSE'], color='blue', label='ground truth')\n",
    "plt.legend()\n",
    "plt.title(f\"Forecasts at max lead time ({lead_time} samples) - Prophet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-battery",
   "metadata": {},
   "source": [
    "With the help of the ForecastingDataset class defined earlier, iterate over each forecast and ground truth pair, and compute and collect multiple evaluation metrics as defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_metrics(ground_truth_dataset, forecast_dataset):\n",
    "        \n",
    "    errors = {metric_name:[] for metric_name in metrics.keys()}\n",
    "\n",
    "    for i in range(len(forecast_dataset)):\n",
    "        x, y, x_d, y_d = forecast_dataset[i]\n",
    "        x_gt, y_gt, x_gt_d, y_gt_d = ground_truth_dataset[i]\n",
    "        for metric_name, metric_fn in metrics.items(): \n",
    "            errors[metric_name].append(metric_fn(y_true=y_gt['USD_CLOSE'], y_pred=y))\n",
    "    \n",
    "    return errors\n",
    "\n",
    "error_metrics = compute_error_metrics(test_dataset, forecast_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_stats = compute_error_statistics(error_metrics, 'prophet')\n",
    "prophet_stats['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-cyprus",
   "metadata": {
    "id": "speaking-physiology"
   },
   "source": [
    "Let's now collect the mean evaluation metrics into a new DataFrame that we will use for comparative evalution against other models' forecasts.\n",
    "\n",
    "Please note that the comparison is not completely fair - Prophet has to predict 672 steps into the future at once, whereas our baselines only have to predict the next 60 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-denial",
   "metadata": {
    "id": "canadian-coating"
   },
   "outputs": [],
   "source": [
    "results_df = results_df.append(prophet_stats['mean'])\n",
    "results_df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-airline",
   "metadata": {
    "id": "interracial-karen"
   },
   "source": [
    "# NeuralProphet\n",
    "\n",
    "Let's proceed to explore the [NeuralProphet](https://neuralprophet.com/html/index.html) model. Please review the following resources to learn more:\n",
    "\n",
    "- [Paper](https://arxiv.org/abs/2111.15397)\n",
    "- [Documentation](https://neuralprophet.com/html/contents.html)\n",
    "- [GitHub](https://github.com/ourownstory/neural_prophet)\n",
    "\n",
    "In the words of its developers, NeuralProphet is \"*based on neural networks, inspired by Facebook Prophet and AR-Net, built on PyTorch*\". A very important differentiating feature is that NeuralProphet conveniently supports *lagged regressors*. In the context of this running example, NeuralProphet supports the use of multiple other currencies' time series. With this expanded flexibility, however, the model is more complex, with a greater number of design choices and hyperparameters to consider. \n",
    "\n",
    "The official [documentation on lagged regressors (lagged covariates)](https://neuralprophet.com/html/lagged_covariates_energy_ercot.html) gives several examples for configuring NeuralProphet models to use lagged regressors, but commentary and suggestions on best practices are largely absent. \n",
    "\n",
    "In the following code, we will consider a small number of NeuralProphet model configurations applied to the same forecasting task from above. Importantly, we retain the same train/test (in-sample/out-of-sample) split, and we will apply the same evaluation metrics to NeuralProphet's forecasts. \n",
    "\n",
    "### Data Formatting\n",
    "\n",
    "NeuralProphet's data format is very similar to Prophet's. We prepare new DataFrames for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-cache",
   "metadata": {
    "id": "placed-cooper"
   },
   "outputs": [],
   "source": [
    "np_train_df = train_df.reset_index().rename({'date':'ds', 'USD_CLOSE':'y'}, axis=1).drop('index', axis=1)\n",
    "np_test_df = test_df.reset_index().rename({'date':'ds','USD_CLOSE':'y'}, axis=1).drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-nepal",
   "metadata": {},
   "source": [
    "Of course the most important difference between the DataFrames prepared for Prophet and NeuralProphet is that, with NeuralProphet, we have the opportunity to include data about the non-target variables as lagged regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-protection",
   "metadata": {
    "id": "round-attitude"
   },
   "source": [
    "## Baseline/Default Model\n",
    "\n",
    "A baseline NeuralProphet model with lagged regressors using default initialization parameters, except:\n",
    "\n",
    "- `n_lags=lag_time`, specifying that the autoregressive component of the model should use the past `lag_time` daily observations as inputs\n",
    "- `n_forecasts=lead_time`, specifying that our use case is to predict the target signal `lead_time` days into the future\n",
    "\n",
    "NeuralProphet also allows you to specify a `validation_df` in `fit()`, on which the model will be evaluated every epoch. We are not using this feature here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-panama",
   "metadata": {
    "id": "external-detection",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_model = NeuralProphet(n_lags=lag_time, n_forecasts=lead_time)\n",
    "\n",
    "# Add the non-target feature columns as lagged regressors\n",
    "feature_cols = [col for col in np_train_df if col not in ('USD_CLOSE', 'ds', 'y')]\n",
    "for feature in feature_cols:\n",
    "    np_model.add_lagged_regressor(f'{feature}')\n",
    "    \n",
    "np_model.fit(np_train_df, freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-prefix",
   "metadata": {},
   "source": [
    "After fitting, you can plot the learned model parameters, including the additional 11 lagged regressors (with 90 day lead time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model.plot_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-crown",
   "metadata": {
    "id": "TOY5P1Hq2Ned"
   },
   "source": [
    "NeuralProphet, rather annoyingly, does not collect forecasts into a single yhat variable, but rather into separate `stepX`s for each of the lead times. For example, the following is a single 60-day forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, x_d, y_d = test_dataset[0]\n",
    "x = x.reset_index().rename({'date':'ds', 'USD_CLOSE':'y'}, axis=1).drop('index', axis=1)\n",
    "x = x.assign(ds=x_d.reset_index().drop('index', axis=1).values)\n",
    "y = y.reset_index().rename({'date':'ds', 'USD_CLOSE':'y'}, axis=1).drop('index', axis=1)\n",
    "\n",
    "np_future_df = np_model.make_future_dataframe(x, periods=len(y))\n",
    "np_forecast = np_model.predict(np_future_df, decompose=False, raw=True)\n",
    "np_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-jewel",
   "metadata": {},
   "source": [
    "To get a more useable data structure, the following function takes a NeuralProphet forecast dataframe and turns it into a time series of its predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yhat_from_neuralprophet_forecast(np_forecast, y_d):\n",
    "    return pd.Series(np_forecast.T.iloc[1:].set_index(y_d).iloc[:,0], name='np_yhat').rename_axis('ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-array",
   "metadata": {},
   "source": [
    "The forecast from above would now look this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_from_neuralprophet_forecast(np_forecast, y_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-stylus",
   "metadata": {},
   "source": [
    "Since NeuralProphet uses a fixed-size input sequence (lagged observations) to produce forecasts, we iterate over the input sequences in the test set and use them as model inputs to produce forecasts. This mode of inference should be more familiar to machine learning practitioners than Prophet's. Note that NeuralProphet requires us to first format input data using the `make_future_dataframe` function before running inference using the `predict` function. We define the following function, which produces forecasts for each of the input/ground-truth-output sequences in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_np_forecasts(np_model, test_dataset):\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    for i in range(len(test_dataset)):\n",
    "        \n",
    "        x, y, x_d, y_d = test_dataset[i]\n",
    "        x = x.reset_index().rename({'date':'ds', 'USD_CLOSE':'y'}, axis=1).drop('index', axis=1)\n",
    "        x = x.assign(ds=x_d.reset_index().drop('index', axis=1).values)\n",
    "        y = y.reset_index().rename({'date':'ds', 'USD_CLOSE':'y'}, axis=1).drop('index', axis=1)\n",
    "\n",
    "        np_future_df = np_model.make_future_dataframe(x, periods=len(y))\n",
    "        np_forecast = np_model.predict(np_future_df, decompose=False, raw=True)\n",
    "        fc_series = yhat_from_neuralprophet_forecast(np_forecast, y_d)\n",
    "        forecasts.append(fc_series)\n",
    "\n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-death",
   "metadata": {},
   "source": [
    "Similarly to what we defined for Prophet, we define the following function for computing and collecting evaluation metrics over all of the forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-tomorrow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "guided-local",
    "outputId": "3adad78b-e26f-4c49-a9b1-f39439ff1984"
   },
   "outputs": [],
   "source": [
    "def compute_np_error_metrics(forecasts):\n",
    "\n",
    "    errors = {metric_name:[] for metric_name in metrics.keys()}\n",
    "\n",
    "    for i in range(len(forecasts)):\n",
    "        \n",
    "        fc = forecasts[i]\n",
    "        gt = test_df.loc[test_df.date.isin(fc.index)].sort_values('date')  # Sorting because I am not 100% sure that the 'isin' function always preserves order.\n",
    "        \n",
    "        for metric_name, metric_fn in metrics.items(): \n",
    "                errors[metric_name].append(metric_fn(y_true=gt['USD_CLOSE'], y_pred=fc))\n",
    "\n",
    "    return errors, forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = collect_np_forecasts(np_model, test_dataset)\n",
    "np_baseline_error_metrics, fcs = compute_np_error_metrics(forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-relation",
   "metadata": {},
   "source": [
    "### Plot all forecasts\n",
    "\n",
    "We have the option to visualize complete forecasts at every time step, but it does not tell us much about the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "\n",
    "for i in range(len(forecasts)):\n",
    "\n",
    "    fc = forecasts[i]\n",
    "    gt = test_df.loc[test_df.date.isin(fc.index)]\n",
    "\n",
    "    ax.plot(fc.index[:], fc[:], alpha=0.1, color='red')\n",
    "    ax.plot(gt.date, gt['USD_CLOSE'], alpha=0.1, color='blue')\n",
    "plt.title(f\"Forecasts at all lead times (1 to {lead_time} samples)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-windsor",
   "metadata": {},
   "source": [
    "### Plot all forecasts at max lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fcs = [{'date': fc.index[-1:][0], 'yhat':fc[-1:][0]} for fc in forecasts]\n",
    "max_fcs = pd.DataFrame(max_fcs)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(test_df.date, test_df['USD_CLOSE'], color='blue', label='ground truth')\n",
    "plt.plot(max_fcs.date, max_fcs.yhat, color='red', label='forecast')\n",
    "plt.title(f\"Forecasts at max lead time ({lead_time} samples) - Neural Prophet Default\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth\n",
    "plt.figure(figsize=(12,3))\n",
    "ground_truth = test_df[['date', 'USD_CLOSE']]\n",
    "plt.plot(ground_truth.date, ground_truth['USD_CLOSE'], label='ground truth')\n",
    "\n",
    "# Plot example single forecast\n",
    "plt.plot(forecasts[-1], label='forecast')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-employer",
   "metadata": {},
   "source": [
    "### Append evaluation metrics to `results_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.append(compute_error_statistics(np_baseline_error_metrics, 'neural_prophet_baseline')['mean'])\n",
    "results_df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-honor",
   "metadata": {
    "id": "E8ko7L71DXSB"
   },
   "source": [
    "## Restricted model\n",
    "\n",
    "The baseline NeuralProphet model does not perform well on out-of-sample data. We can consider multiple changes to the model's configuration and hyperparameters in pursuit of better performance. Let's consider the following configuration that restricts the model to using only the last observed value of last regressors, as opposed to `n_lags` past observations. While less expressive, this model may be less prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_last_sample_only = NeuralProphet(n_lags=lag_time, n_forecasts=lead_time)\n",
    "\n",
    "# Add the non-target feature columns as lagged regressors\n",
    "feature_cols = [col for col in np_train_df if col not in ('USD_CLOSE', 'ds', 'y')]\n",
    "for feature in feature_cols:\n",
    "    np_model_last_sample_only.add_lagged_regressor(f'{feature}', n_lags=1)\n",
    "    \n",
    "np_model_last_sample_only.fit(np_train_df, freq='D')\n",
    "forecasts = collect_np_forecasts(np_model_last_sample_only, test_dataset)\n",
    "np_last_sample_only_error_metrics, fcs = compute_np_error_metrics(forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-theme",
   "metadata": {},
   "source": [
    "Once again, we are able to plot the learned parameters of the model. The lagged regressors are now grouped together in a single chart, as only one value of each is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_last_sample_only.plot_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-blanket",
   "metadata": {},
   "source": [
    "### Plot forecasts at max lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fcs = [{'date': fc.index[-1:][0], 'yhat':fc[-1:][0]} for fc in forecasts]\n",
    "max_fcs = pd.DataFrame(max_fcs)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(test_df.date, test_df['USD_CLOSE'], color='blue', label='ground truth')\n",
    "plt.plot(max_fcs.date, max_fcs.yhat, color='red', label='forecast')\n",
    "plt.title(f\"Forecasts at max lead time ({lead_time} samples) - Neural Prophet 1-Step Lag\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth\n",
    "plt.figure(figsize=(12,3))\n",
    "ground_truth = test_df[['date', 'USD_CLOSE']]\n",
    "plt.plot(ground_truth.date, ground_truth['USD_CLOSE'], label='ground truth')\n",
    "\n",
    "# Plot example single forecast\n",
    "plt.plot(forecasts[-1], label='forecast')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-discussion",
   "metadata": {},
   "source": [
    "### Append evaluation metrics to `results_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.append(compute_error_statistics(np_last_sample_only_error_metrics, 'neural_prophet_last_sample_only')['mean'])\n",
    "results_df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-macedonia",
   "metadata": {
    "id": "rNDiJ6ZZwx6k"
   },
   "source": [
    "## Model with Sparse Neural Autoregression\n",
    "\n",
    "In the previous parameter plots, you could see high values for all autoregressive features. You can tell NeuralProphet to try avoiding relying on them too much by restricting how many of them it is able to use. In this case, we set `ar_reg` to 10, which imposes a strong regularization of the AR model towards sparsity in its coefficients. We also reduce the AR depth to 10 days. *Note*: NeuralProphet applies this sparsity factor only to the regular AR coefficients, not the lagged regressor AR coefficients, where higher sparsity would make more sense.\n",
    "\n",
    "We can also play around with parameters like the number of hidden layers or the learning rate of the AR-Net. Another change applied to this model is the loss function, now MAE instead of the default Huber loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_sparse_nar = NeuralProphet(n_lags=10, \n",
    "                                    n_forecasts=lead_time,\n",
    "                                    ar_reg=10,\n",
    "                                    learning_rate=5e-3,\n",
    "                                    num_hidden_layers=2,\n",
    "                                    d_hidden=16,\n",
    "                                    loss_func='MAE'\n",
    "                                    )\n",
    "\n",
    "# Add the non-target feature columns as lagged regressors\n",
    "feature_cols = [col for col in np_train_df if col not in ('USD_CLOSE', 'ds', 'y')]\n",
    "for feature in feature_cols:\n",
    "    np_model_sparse_nar.add_lagged_regressor(f'{feature}', n_lags=1)\n",
    "    \n",
    "np_model_sparse_nar.fit(np_train_df, freq='D')\n",
    "forecasts = collect_np_forecasts(np_model_sparse_nar, test_dataset)\n",
    "np_sparse_ar_error_metrics, fcs = compute_np_error_metrics(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_sparse_nar.plot_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-memorial",
   "metadata": {},
   "source": [
    "### Plot forecasts at max lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-corrections",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "gJszSXMA0NJO",
    "outputId": "55eff862-a844-4622-d509-d0978776eecf"
   },
   "outputs": [],
   "source": [
    "max_fcs = [{'date': fc.index[-1:][0], 'yhat':fc[-1:][0]} for fc in forecasts]\n",
    "max_fcs = pd.DataFrame(max_fcs)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(test_df.date, test_df['USD_CLOSE'], color='blue', label='ground truth')\n",
    "plt.plot(max_fcs.date, max_fcs.yhat, color='red', label='forecast')\n",
    "plt.title(f\"Forecasts at max lead time ({lead_time} samples) - Neural Prophet Sparse\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth\n",
    "plt.figure(figsize=(12,3))\n",
    "ground_truth = test_df[['date', 'USD_CLOSE']]\n",
    "plt.plot(ground_truth.date, ground_truth['USD_CLOSE'], label='ground truth')\n",
    "\n",
    "# Plot example single forecast\n",
    "plt.plot(forecasts[-1], label='forecast')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-hawaiian",
   "metadata": {},
   "source": [
    "### Append evaluation metrics to `results_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.append(compute_error_statistics(np_sparse_ar_error_metrics, 'neural_prophet_sparse_ar')['mean'])\n",
    "results_df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-texture",
   "metadata": {
    "id": "J7GuAAzvwUNF"
   },
   "source": [
    "# Reflections and Next Steps\n",
    "\n",
    "So far, the best performing 'model' is the persistence forecasting model. This is, of course, an unsatisfactory result. The best performing experimental model on the exchange rates dataset is the restricted NeuralProphet model that uses only the last observation of lagged regressors as features. Of course, we have only considered a very small number of configurations using NeuralProphet, many more model and hyperparameter configurations are possible. Please refer to the [NeuralProphet documentation](https://neuralprophet.com/html/contents.html) for detailed information. However, to *find* a better configuration may require significant effort, either manual or automated (via a hyperparameter search, for example). In practical forecasting use cases, it may be important to consider the time, resources, and effort that are needed to find a forecasting model that is better than  baseline.\n",
    "\n",
    "The following notebooks in this series will cover additional models (N-BEATS and DeepAR) as well as rolling cross validation using NeuralProphet. In order to compare the out-of-sample forecasts produced by this notebook to others, the `results_df` DataFrame is saved below. Hopefully we will find a model that performs better than baseline in a continued out-of-sample evaluation experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b269b3",
   "metadata": {},
   "source": [
    "*Note* The path here should be changed to your local drive folder in order for it to be retrieved in other notebooks. See the beginning of this notebook for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-assistant",
   "metadata": {
    "id": "AWA0tjyfGQWD"
   },
   "outputs": [],
   "source": [
    "output_filename = \"/h/kkoch/forecasting-bootcamp/demos/exchange_rate_mean_test_metrics.csv\"\n",
    "results_df.to_csv(output_filename)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exchange_dataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "e7915587377f13d9edba30ea11b3c98d6b26a63b60775c72ad031792b92d4187"
  },
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "forecasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
